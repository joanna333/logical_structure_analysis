{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Uses BioBERT pre-trained model for medical domain embeddings**\n",
        "\n",
        "Supports GPU acceleration\n",
        "Generates embeddings by:\n",
        "\n",
        "**Tokenizing both sentences**\n",
        "Generating embeddings using mean pooling\n",
        "Concatenating embeddings from both sentences\n",
        "\n",
        "\n",
        "**Saves embeddings and relationships to a .npz file**\n",
        "Provides error handling and progress tracking"
      ],
      "metadata": {
        "id": "bXoSBBc5zilm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "ooHdTQzSkN2W"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_biobert_embeddings(csv_path: str, output_path: str = \"biobert_embeddings.npz\"):\n",
        "    \"\"\"\n",
        "    Create embeddings from a CSV file using BioBERT.\n",
        "\n",
        "    :param csv_path: Path to the CSV file with columns: 'first_sentence', 'second_sentence', 'relationship'.\n",
        "    :param output_path: Path to save the embeddings as a .npz file.\n",
        "    \"\"\"\n",
        "    # Load the dataset\n",
        "    try:\n",
        "        data = pd.read_csv(csv_path)\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Error reading CSV file: {e}\")\n",
        "\n",
        "    # Check required columns\n",
        "    required_columns = ['Sentence 1', 'Sentence 2', 'Relationship']\n",
        "    if not all(column in data.columns for column in required_columns):\n",
        "        raise ValueError(f\"CSV file must contain the following columns: {required_columns}\")\n",
        "\n",
        "    # Load BioBERT tokenizer and model\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
        "    model = AutoModel.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    # Return the model, tokenizer, and data  # This line is modified\n",
        "    return model, tokenizer, data"
      ],
      "metadata": {
        "id": "qaUZSEAm8fCJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the function and get the model and tokenizer\n",
        "model, tokenizer, data = create_biobert_embeddings(\"/content/Data_relationships.csv\") # Replace with your actual CSV file path"
      ],
      "metadata": {
        "id": "H2IvJmjyy86Q"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # Determine device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FB628Z66ycyK",
        "outputId": "d8976dde-c27f-488a-855f-54723c0472ed"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSdpaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare to store embeddings and metadata\n",
        "sentence_embeddings = []\n",
        "relationships = []"
      ],
      "metadata": {
        "id": "AzuNckLh0CNW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get sentence embedding\n",
        "def get_sentence_embedding(sentence):\n",
        "    # Tokenize the sentence\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Get model embeddings\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Mean pooling to get sentence embedding\n",
        "    token_embeddings = outputs.last_hidden_state\n",
        "    attention_mask = inputs['attention_mask']\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    embedding = torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "    return embedding.cpu().numpy()"
      ],
      "metadata": {
        "id": "HpTRZGmd1dB7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process sentences and generate embeddings\n",
        "def process_sentences_generate_embeddings(data, tokenizer, model, sentence_embeddings, relationships):\n",
        "    for _, row in tqdm(data.iterrows(), total=len(data), desc=\"Generating Embeddings\"):\n",
        "        try:\n",
        "            # Get embeddings for both sentences\n",
        "            first_embedding = get_sentence_embedding(row['Sentence 1'], tokenizer, model) # Use 'Sentence 1'\n",
        "            second_embedding = get_sentence_embedding(row['Sentence 2'], tokenizer, model) # Use 'Sentence 2'\n",
        "\n",
        "            # Combine embeddings\n",
        "            combined_embedding = np.concatenate([first_embedding, second_embedding])\n",
        "            sentence_embeddings.append(combined_embedding)\n",
        "            relationships.append(row['Relationship']) # Use 'Relationship'\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing row: {e}\")\n",
        "            continue\n",
        "    return sentence_embeddings, relationships"
      ],
      "metadata": {
        "id": "63j1WEnn1xsX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process sentences and generate embeddings\n",
        "def process_sentences_generate_embeddings(data, tokenizer, model, sentence_embeddings, relationships):\n",
        "    for _, row in tqdm(data.iterrows(), total=len(data), desc=\"Generating Embeddings\"):\n",
        "        try:\n",
        "            # Get embeddings for both sentences\n",
        "            first_embedding = get_sentence_embedding(row['Sentence 1'], tokenizer, model) # Use 'Sentence 1'\n",
        "            second_embedding = get_sentence_embedding(row['Sentence 2'], tokenizer, model) # Use 'Sentence 2'\n",
        "\n",
        "            # Combine embeddings\n",
        "            combined_embedding = np.concatenate([first_embedding, second_embedding])\n",
        "            sentence_embeddings.append(combined_embedding)\n",
        "            relationships.append(row['Relationship']) # Use 'Relationship'\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing row: {e}\")\n",
        "            continue\n",
        "    return sentence_embeddings, relationships"
      ],
      "metadata": {
        "id": "8nwxvcfM3EZf"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process sentences and generate embeddings\n",
        "def process_sentences_generate_embeddings(data, output_path: str = \"biobert_embeddings.npz\"):\n",
        "    sentence_embeddings = []\n",
        "    relationships = []\n",
        "    for _, row in tqdm(data.iterrows(), total=len(data), desc=\"Generating Embeddings\"):\n",
        "        try:\n",
        "            # Get embeddings for both sentences\n",
        "            first_embedding = get_sentence_embedding(row['Sentence 1'])\n",
        "            second_embedding = get_sentence_embedding(row['Sentence 2'])\n",
        "\n",
        "            # Combine embeddings\n",
        "            combined_embedding = np.concatenate([first_embedding, second_embedding])\n",
        "            sentence_embeddings.append(combined_embedding)\n",
        "            relationships.append(row['Relationship'])\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing row: {e}\")\n",
        "            continue\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    sentence_embeddings = np.array(sentence_embeddings)\n",
        "    relationships = np.array(relationships)\n",
        "\n",
        "    # Save embeddings and relationships\n",
        "    np.savez(\n",
        "        output_path,\n",
        "        embeddings=sentence_embeddings,\n",
        "        relationships=relationships\n",
        "    )\n",
        "\n",
        "    print(f\"Embeddings saved to {output_path}\")\n",
        "    print(f\"Embeddings shape: {sentence_embeddings.shape}\")\n",
        "    print(f\"Relationships shape: {relationships.shape}\")\n",
        "\n",
        "    return sentence_embeddings, relationships\n",
        "\n"
      ],
      "metadata": {
        "id": "XTbWEECR7XxA"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Replace with your actual CSV path\n",
        "    csv_path = \"/content/Data_relationships.csv\"\n",
        "    output_path = \"biobert_embeddings.npz\"\n",
        "\n",
        "    # Modify this line to unpack all three returned values\n",
        "    model, tokenizer, data = create_biobert_embeddings(csv_path, output_path)\n",
        "\n",
        "    # Now call process_sentences_generate_embeddings with the necessary arguments\n",
        "    embeddings, rels = process_sentences_generate_embeddings(data, output_path) # Pass data and output_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrCiiAqN9RP4",
        "outputId": "37c191c9-7637-44c0-bd75-b5972a52fe62"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating Embeddings: 100%|██████████| 250/250 [01:01<00:00,  4.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings saved to biobert_embeddings.npz\n",
            "Embeddings shape: (250, 2, 768)\n",
            "Relationships shape: (250,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**#To Read Embedding Files#**"
      ],
      "metadata": {
        "id": "vpBXaEko-cM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load the .npz file\n",
        "data = np.load('/content/biobert_embeddings.npz')\n",
        "\n",
        "# List all the arrays stored in the .npz file\n",
        "print(data.files)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLbee-LG-QOs",
        "outputId": "85c46a4f-7022-44c1-df31-cecea0eb7ad8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['embeddings', 'relationships']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access a specific array by its name (for example, 'embedding')\n",
        "embedding = data['embeddings']\n",
        "\n",
        "# Print the embedding array (or do further processing)\n",
        "print(embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NizEN-w7-tee",
        "outputId": "a5c41d28-ac32-48e8-a37c-ba3158cd871a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[-0.26180524 -0.00606371 -0.09929299 ... -0.03283149 -0.07074795\n",
            "   -0.07370254]\n",
            "  [-0.052624   -0.10554495 -0.23050874 ... -0.04975342 -0.03628622\n",
            "   -0.23326284]]\n",
            "\n",
            " [[-0.06664198 -0.05004142 -0.12933666 ...  0.03189946  0.15915684\n",
            "   -0.18128423]\n",
            "  [-0.17897642 -0.10246386 -0.22736183 ...  0.10066219  0.22736196\n",
            "   -0.26042587]]\n",
            "\n",
            " [[-0.07911068  0.05578955  0.03445188 ...  0.09288554  0.06558892\n",
            "   -0.1920433 ]\n",
            "  [-0.16268839  0.10344014 -0.1179441  ... -0.01996229  0.09928265\n",
            "   -0.23303708]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.13020998  0.19109687  0.09628036 ... -0.06239978  0.2223844\n",
            "   -0.19263579]\n",
            "  [-0.15140349  0.1632779   0.07422288 ...  0.02373421  0.2683528\n",
            "   -0.32095304]]\n",
            "\n",
            " [[-0.00179012  0.21672682 -0.15787332 ...  0.18023299  0.09780022\n",
            "   -0.0065886 ]\n",
            "  [ 0.10490052  0.0658789  -0.18372914 ...  0.17768392  0.06081073\n",
            "   -0.24605867]]\n",
            "\n",
            " [[-0.18936013  0.21297717 -0.16273376 ... -0.00419721  0.02917262\n",
            "   -0.21053913]\n",
            "  [-0.16725007  0.29874015 -0.00400542 ... -0.04367919  0.04564876\n",
            "   -0.07530328]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access a specific array by its name (for example, 'embedding')\n",
        "relationship = data['relationships']\n",
        "\n",
        "# Print the embedding array (or do further processing)\n",
        "print(relationship)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrlDTMAH-4xr",
        "outputId": "95f89047-6b8a-43dd-a576-801082d8f316"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['causality' 'causality' 'causality' 'causality' 'causality' 'causality'\n",
            " 'causality' 'causality' 'causality' 'causality' 'condition' 'condition'\n",
            " 'condition' 'condition' 'condition' 'condition' 'condition' 'condition'\n",
            " 'condition' 'condition' 'sequence' 'sequence' 'sequence' 'sequence'\n",
            " 'sequence' 'sequence' 'sequence' 'sequence' 'sequence' 'sequence'\n",
            " 'comparison' 'comparison' 'comparison' 'comparison' 'comparison'\n",
            " 'comparison' 'comparison' 'comparison' 'comparison' 'comparison'\n",
            " 'sequence' 'sequence' 'sequence' 'sequence' 'sequence' 'condition'\n",
            " 'condition' 'comparison' 'comparison' 'comparison' 'causality'\n",
            " 'causality' 'causality' 'sequence' 'causality' 'causality' 'causality'\n",
            " 'sequence' 'causality' 'causality' 'causality' 'causality' 'causality'\n",
            " 'causality' 'causality' 'causality' 'condition' 'sequence' 'sequence'\n",
            " 'sequence' 'comparison' 'comparison' 'condition' 'causality' 'causality'\n",
            " 'causality' 'sequence' 'causality' 'sequence' 'causality' 'causality'\n",
            " 'causality' 'causality' 'comparison' 'comparison' 'causality' 'causality'\n",
            " 'causality' 'sequence' 'causality' 'causality' 'comparison' 'condition'\n",
            " 'comparison' 'comparison' 'causality' 'causality' 'causality' 'causality'\n",
            " 'sequence' 'causality' 'causality' 'condition' 'causality' 'sequence'\n",
            " 'causality' 'causality' 'causality' 'condition' 'sequence' 'causality'\n",
            " 'sequence' 'causality' 'causality' 'causality' 'causality' 'causality'\n",
            " 'causality' 'causality' 'sequence' 'causality' 'causality' 'causality'\n",
            " 'causality' 'causality' 'causality' 'causality' 'causality' 'causality'\n",
            " 'sequence' 'causality' 'condition' 'comparison' 'comparison' 'comparison'\n",
            " 'comparison' 'comparison' 'comparison' 'comparison' 'comparison'\n",
            " 'comparison' 'comparison' 'comparison' 'comparison' 'comparison'\n",
            " 'comparison' 'comparison' 'comparison' 'comparison' 'comparison'\n",
            " 'causality' 'causality' 'causality' 'causality' 'causality' 'causality'\n",
            " 'causality' 'causality' 'causality' 'causality' 'causality' 'causality'\n",
            " 'causality' 'condition' 'causality' 'causality' 'causality' 'causality'\n",
            " 'causality' 'causality' 'sequence' 'sequence' 'causality' 'causality'\n",
            " 'causality' 'condition' 'sequence' 'sequence' 'causality' 'condition'\n",
            " 'comparison' 'condition' 'condition' 'comparison' 'comparison'\n",
            " 'causality' 'causality' 'condition' 'causality' 'comparison' 'sequence'\n",
            " 'causality' 'causality' 'causality' 'causality' 'causality' 'causality'\n",
            " 'comparison' 'comparison' 'comparison' 'causality' 'causality'\n",
            " 'causality' 'causality' 'causality' 'causality' 'causality' 'causality'\n",
            " 'causality' 'causality' 'condition' 'condition' 'condition' 'condition'\n",
            " 'condition' 'condition' 'condition' 'condition' 'condition' 'condition'\n",
            " 'sequence' 'sequence' 'sequence' 'sequence' 'sequence' 'sequence'\n",
            " 'sequence' 'sequence' 'sequence' 'sequence' 'comparison' 'comparison'\n",
            " 'comparison' 'comparison' 'comparison' 'comparison' 'comparison'\n",
            " 'comparison' 'comparison' 'comparison' 'sequence' 'sequence' 'sequence'\n",
            " 'sequence' 'sequence' 'condition' 'condition' 'comparison' 'comparison'\n",
            " 'comparison']\n"
          ]
        }
      ]
    }
  ]
}