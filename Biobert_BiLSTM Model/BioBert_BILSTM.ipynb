{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-ZuwxXdsAfR6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import joblib\n",
        "import multiprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxFyjZLkBSez",
        "outputId": "fc943564-2f5a-4b76-e4eb-3c30f3c14439"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_folder = \"/content/drive/MyDrive/Data folder\"\n",
        "output_folder = \"/content/drive/MyDrive/Output folder\""
      ],
      "metadata": {
        "id": "qVeFzkakBZeo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BioBERTEmbeddingProcessor:\n",
        "    def __init__(self, model_name=\"dmis-lab/biobert-base-cased-v1.1\"):\n",
        "        \"\"\"\n",
        "        Initialize BioBERT tokenizer and model for embedding generation\n",
        "\n",
        "        Args:\n",
        "            model_name (str): Hugging Face model identifier\n",
        "        \"\"\"\n",
        "        # Device configuration\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # Load tokenizer and model\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
        "        self.model = AutoModel.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\").to(self.device)\n",
        "        self.model.eval()\n",
        "\n",
        "        # Label encoder to manage categorical labels\n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "    def generate_word_embeddings(self, sentence): # Added this function inside the class\n",
        "        \"\"\"\n",
        "        Generate word-level embeddings for a given sentence\n",
        "\n",
        "        Args:\n",
        "            sentence (str): Input sentence\n",
        "\n",
        "        Returns:\n",
        "            list: Word embeddings\n",
        "        \"\"\"\n",
        "        # Tokenize the sentence\n",
        "        tokens = self.tokenizer(sentence, return_tensors=\"pt\",\n",
        "                                padding=True,\n",
        "                                truncation=True,\n",
        "                                max_length=512).to(self.device)\n",
        "\n",
        "        # Generate embeddings\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**tokens)\n",
        "\n",
        "        # Extract embeddings\n",
        "        embeddings = outputs.last_hidden_state.squeeze(0)\n",
        "        token_ids = tokens['input_ids'].squeeze(0)\n",
        "        words = self.tokenizer.convert_ids_to_tokens(token_ids)\n",
        "\n",
        "        # Filter out special tokens\n",
        "        results = []\n",
        "        for i, word in enumerate(words):\n",
        "            if word not in [\"[CLS]\", \"[SEP]\", \"[PAD]\"]:\n",
        "                results.append({\n",
        "                    \"word\": word,\n",
        "                    \"embedding\": embeddings[i].cpu().tolist()\n",
        "                })\n",
        "\n",
        "        return results\n",
        "\n",
        "    def process_csv_files(self, input_folder, output_folder, num_workers=None): # Added this function inside the class\n",
        "        \"\"\"\n",
        "        Process CSV files in parallel to generate embeddings\n",
        "\n",
        "        Args:\n",
        "            input_folder (str): Folder containing input CSV files\n",
        "            output_folder (str): Folder to save processed embeddings\n",
        "            num_workers (int, optional): Number of parallel workers\n",
        "        \"\"\"\n",
        "        # Ensure output folder exists\n",
        "        os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "        # Get list of CSV files\n",
        "        csv_files = [f for f in os.listdir(input_folder) if f.endswith('.csv')]\n",
        "\n",
        "        # Use multiprocessing to speed up processing\n",
        "        if num_workers is None:\n",
        "            num_workers = max(1, multiprocessing.cpu_count() - 1)\n",
        "\n",
        "        with multiprocessing.Pool(num_workers) as pool:\n",
        "            # Prepare arguments for each file\n",
        "            args = [(os.path.join(input_folder, file),\n",
        "                     os.path.join(output_folder, file),\n",
        "                     self) for file in csv_files]\n",
        "\n",
        "             # Process files in parallel\n",
        "            pool.starmap(self._process_single_file, args)\n",
        "\n",
        "    def _process_single_file(self, input_path, output_path, processor):\n",
        "        \"\"\"\n",
        "        Process a single CSV file\n",
        "\n",
        "        Args:\n",
        "            input_path (str): Path to input CSV\n",
        "            output_path (str): Path to output CSV\n",
        "            processor (BioBERTEmbeddingProcessor): Processor instance\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Read input CSV\n",
        "            df = pd.read_csv(input_path)\n",
        "\n",
        "            # Prepare output data\n",
        "            all_embeddings = []\n",
        "\n",
        "            # Process each row\n",
        "            for _, row in df.iterrows():\n",
        "                sentence = row['Sentence']\n",
        "                label = row['Label']\n",
        "\n",
        "                # Generate word embeddings\n",
        "                word_embeddings = processor.generate_word_embeddings(sentence)\n",
        "\n",
        "                # Collect embeddings with labels\n",
        "                for item in word_embeddings:\n",
        "                    all_embeddings.append({\n",
        "                        \"Word\": item['word'],\n",
        "                        \"Embedding\": item['embedding'],\n",
        "                        \"Label\": label\n",
        "                    })\n",
        "\n",
        "            # Save processed data\n",
        "            output_df = pd.DataFrame(all_embeddings)\n",
        "            output_df.to_csv(output_path, index=False)\n",
        "            print(f\"Processed {input_path} -> {output_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {input_path}: {e}\")\n",
        ""
      ],
      "metadata": {
        "id": "xFibIekMEvkQ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BiLSTMClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, dropout=0.5):\n",
        "        \"\"\"\n",
        "        Bidirectional LSTM Classifier\n",
        "\n",
        "        Args:\n",
        "            input_dim (int): Embedding dimension\n",
        "            hidden_dim (int): LSTM hidden layer dimension\n",
        "            output_dim (int): Number of output classes\n",
        "            dropout (float): Dropout rate\n",
        "        \"\"\"\n",
        "        super(BiLSTMClassifier, self).__init__()\n",
        "\n",
        "        # Bidirectional LSTM\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_dim,\n",
        "            hidden_dim,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "\n",
        "        # Dropout for regularization\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Fully connected output layer\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the network\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input embeddings\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output logits\n",
        "        \"\"\"\n",
        "        # LSTM processing\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "\n",
        "        # Take the last hidden state\n",
        "        lstm_out = lstm_out[:, -1, :]\n",
        "\n",
        "        # Apply dropout\n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "\n",
        "        # Generate output\n",
        "        output = self.fc(lstm_out)\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "8H8qyvZVB0wM"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BioBERTBiLSTMClassificationPipeline:\n",
        "    def __init__(self, embedding_dim=768, hidden_dim=128):\n",
        "        \"\"\"\n",
        "        End-to-end BioBERT BiLSTM Classification Pipeline\n",
        "\n",
        "        Args:\n",
        "            embedding_dim (int): Dimension of BioBERT embeddings\n",
        "            hidden_dim (int): LSTM hidden layer dimension\n",
        "        \"\"\"\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.embedding_processor = BioBERTEmbeddingProcessor()\n",
        "        self.model = None\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def prepare_data(self, csv_files):\n",
        "        \"\"\"\n",
        "        Prepare data for training\n",
        "\n",
        "        Args:\n",
        "            csv_files (list): List of CSV file paths\n",
        "\n",
        "        Returns:\n",
        "            tuple: Prepared embeddings and labels\n",
        "        \"\"\"\n",
        "        all_embeddings = []\n",
        "        all_labels = []\n",
        "\n",
        "        for filename in csv_files:\n",
        "            df = pd.read_csv(filename)\n",
        "\n",
        "            # CHANGED: Iterate through groups based on 'Sentence' (which is now 'Word')\n",
        "            for sentence, group in df.groupby('Word'):\n",
        "                # Extract embeddings and label for the group\n",
        "                sentence_embeddings = group['Embedding'].apply(eval).tolist() # Convert string representation to list\n",
        "                label = group['Label'].iloc[0]  # Get the label (assuming it's the same for all rows in the group)\n",
        "\n",
        "                all_embeddings.append(sentence_embeddings)\n",
        "                all_labels.append(label)\n",
        "\n",
        "        # Encode labels\n",
        "        all_labels = self.embedding_processor.label_encoder.fit_transform(all_labels)\n",
        "\n",
        "        return all_embeddings, all_labels\n",
        "\n",
        "\n",
        "\n",
        "    def train_model(self, csv_files, test_size=0.2, batch_size=32, epochs=10):\n",
        "        \"\"\"\n",
        "        Train BiLSTM model\n",
        "\n",
        "        Args:\n",
        "            csv_files (list): List of training CSV files\n",
        "            test_size (float): Proportion of test data\n",
        "            batch_size (int): Training batch size\n",
        "            epochs (int): Number of training epochs\n",
        "\n",
        "        Returns:\n",
        "            float: Best validation accuracy\n",
        "        \"\"\"\n",
        "        # Prepare data\n",
        "        embeddings, labels = self.prepare_data(csv_files)\n",
        "\n",
        "        # Split data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            embeddings, labels,\n",
        "            test_size=test_size,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        # Pad sequences to uniform length\n",
        "        max_len = max(len(seq) for seq in embeddings)\n",
        "        X_train = [seq + [[0] * self.embedding_dim] * (max_len - len(seq)) for seq in X_train]\n",
        "        X_test = [seq + [[0] * self.embedding_dim] * (max_len - len(seq)) for seq in X_test]\n",
        "\n",
        "        # Convert to tensors\n",
        "        X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "        X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "        y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "        y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "        # Create data loaders\n",
        "        train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "        test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "        # Initialize model\n",
        "        self.model = BiLSTMClassifier(\n",
        "            input_dim=self.embedding_dim,\n",
        "            hidden_dim=self.hidden_dim,\n",
        "            output_dim=len(set(labels))\n",
        "        ).to(self.device)\n",
        "\n",
        "        # Loss and optimizer\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(self.model.parameters())\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "        # Training loop\n",
        "        best_accuracy = 0\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train()\n",
        "            train_loss = 0\n",
        "\n",
        "            for batch_x, batch_y in train_loader:\n",
        "                batch_x, batch_y = batch_x.to(self.device), batch_y.to(self.device)\n",
        "\n",
        "                # Zero gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = self.model(batch_x)\n",
        "                loss = criterion(outputs, batch_y)\n",
        "\n",
        "                # Backward pass\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += loss.item()\n",
        "\n",
        "            # Validation\n",
        "            self.model.eval()\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch_x, batch_y in test_loader:\n",
        "                    batch_x, batch_y = batch_x.to(self.device), batch_y.to(self.device)\n",
        "                    outputs = self.model(batch_x)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                    total += batch_y.size(0)\n",
        "                    correct += (predicted == batch_y).sum().item()\n",
        "\n",
        "            # Update learning rate\n",
        "            scheduler.step()\n",
        "\n",
        "            # Track best model\n",
        "            accuracy = correct / total\n",
        "            if accuracy > best_accuracy:\n",
        "                best_accuracy = accuracy\n",
        "                torch.save(self.model.state_dict(), 'best_bilstm_model.pth')\n",
        "                joblib.dump(self.embedding_processor.label_encoder, 'label_encoder.pkl')\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{epochs}: Loss = {train_loss/len(train_loader):.4f}, Accuracy = {accuracy:.4f}\")\n",
        "\n",
        "        return best_accuracy\n",
        "\n",
        "    def predict_sentences(self, sentences):\n",
        "        \"\"\"\n",
        "        Predict labels for multiple sentences\n",
        "\n",
        "        Args:\n",
        "            sentences (list): List of sentences to predict\n",
        "\n",
        "        Returns:\n",
        "            list: Predicted labels\n",
        "        \"\"\"\n",
        "        # Ensure model is loaded\n",
        "        if self.model is None:\n",
        "            self.model = BiLSTMClassifier(\n",
        "                input_dim=self.embedding_dim,\n",
        "                hidden_dim=self.hidden_dim,\n",
        "                output_dim=len(self.embedding_processor.label_encoder.classes_)\n",
        "            ).to(self.device)\n",
        "            self.model.load_state_dict(torch.load('best_bilstm_model.pth'))\n",
        "\n",
        "            # Reload label encoder\n",
        "            self.embedding_processor.label_encoder = joblib.load('label_encoder.pkl')\n",
        "\n",
        "        self.model.eval()\n",
        "        predictions = []\n",
        "\n",
        "        for sentence in sentences:\n",
        "            # Generate word embeddings\n",
        "            word_embeddings = self.embedding_processor.generate_word_embeddings(sentence)\n",
        "            sentence_embeddings = [item['embedding'] for item in word_embeddings]\n",
        "\n",
        "            # Pad sequence\n",
        "            max_len = 10  # Or whatever max length you expect\n",
        "            sentence_embeddings = sentence_embeddings[:max_len] + [[0] * self.embedding_dim] * (max_len - len(sentence_embeddings))\n",
        "\n",
        "            # Convert to tensor\n",
        "            sentence_tensor = torch.tensor(sentence_embeddings).unsqueeze(0).float().to(self.device)\n",
        "\n",
        "            # Predict\n",
        "            with torch.no_grad():\n",
        "                output = self.model(sentence_tensor)\n",
        "                predicted_label_idx = output.argmax(dim=1).item()\n",
        "                predicted_label = self.embedding_processor.label_encoder.inverse_transform([predicted_label_idx])[0]\n",
        "                predictions.append(predicted_label)\n",
        "\n",
        "        return predictions"
      ],
      "metadata": {
        "id": "xLboL6-KB6A1"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage\n",
        "def main():\n",
        "    # Initialize the pipeline\n",
        "    pipeline = BioBERTBiLSTMClassificationPipeline()\n",
        "\n",
        "    # Process CSV files (optional)\n",
        "    # CHANGED: Provide the correct path to your input folder if it's not 'input_embeddings'\n",
        "    # For example, if your CSV files are in the 'data' folder:\n",
        "    pipeline.embedding_processor.process_csv_files(\n",
        "        input_folder=input_folder,  # Changed to use the user-defined input_folder\n",
        "        output_folder=output_folder # Changed to use the user-defined output_folder\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    csv_files = [os.path.join(output_folder, f) for f in os.listdir(output_folder) if f.endswith('.csv')] # Changed to use the output_folder and list comprehension\n",
        "    pipeline.train_model(csv_files, epochs=10)\n",
        "\n",
        "    # Predict for multiple sentences\n",
        "    test_sentences = [\n",
        "\n",
        "        \"A gland is an organ that makes one or more substances, such as hormones, digestive juices, sweat or tears.\",\n",
        "        \"Endocrine glands release hormones directly into the bloodstream.\",\n",
        "        \"endocrine system is an elaborate network of glands and hormones..\",\n",
        "        \"A thyroidectomy is the surgical removal of your entire thyroid gland.\",\n",
        "\n",
        "    ]\n",
        "    predictions = pipeline.predict_sentences(test_sentences)\n",
        "\n",
        "    # Print predictions\n",
        "    for sentence, prediction in zip(test_sentences, predictions):\n",
        "        print(f\"Sentence: {sentence}\")\n",
        "        print(f\"Predicted Label: {prediction}\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xS4zQxi1FTbh",
        "outputId": "1c475ada-5a84-4e9d-d0d1-c9728dfba0ed"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed /content/drive/MyDrive/Data folder/blood_pressure_control.csv -> /content/drive/MyDrive/Output folder/blood_pressure_control.csv\n",
            "Processed /content/drive/MyDrive/Data folder/heart_cycle.csv -> /content/drive/MyDrive/Output folder/heart_cycle.csv\n",
            "Processed /content/drive/MyDrive/Data folder/circulatory_flow.csv -> /content/drive/MyDrive/Output folder/circulatory_flow.csv\n",
            "Processed /content/drive/MyDrive/Data folder/dehydration_response.csv -> /content/drive/MyDrive/Output folder/dehydration_response.csv\n",
            "Processed /content/drive/MyDrive/Data folder/exercise_response.csv -> /content/drive/MyDrive/Output folder/exercise_response.csv\n",
            "Processed /content/drive/MyDrive/Data folder/fluid_balance.csv -> /content/drive/MyDrive/Output folder/fluid_balance.csv\n",
            "Processed /content/drive/MyDrive/Data folder/kidney_function.csv -> /content/drive/MyDrive/Output folder/kidney_function.csv\n",
            "Processed /content/drive/MyDrive/Data folder/lung_perfusion_balance.csv -> /content/drive/MyDrive/Output folder/lung_perfusion_balance.csv\n",
            "Processed /content/drive/MyDrive/Data folder/pulmonary_gas_transfer.csv -> /content/drive/MyDrive/Output folder/pulmonary_gas_transfer.csv\n",
            "Processed /content/drive/MyDrive/Data folder/renal_ph_regulation.csv -> /content/drive/MyDrive/Output folder/renal_ph_regulation.csv\n",
            "Processed /content/drive/MyDrive/Data folder/respiratory_acid_base.csv -> /content/drive/MyDrive/Output folder/respiratory_acid_base.csv\n",
            "Processed /content/drive/MyDrive/Data folder/respiratory_control.csv -> /content/drive/MyDrive/Output folder/respiratory_control.csv\n",
            "Processed /content/drive/MyDrive/Data folder/blood_sugar_control.csv -> /content/drive/MyDrive/Output folder/blood_sugar_control.csv\n",
            "Processed /content/drive/MyDrive/Data folder/thyroid_regulation.csv -> /content/drive/MyDrive/Output folder/thyroid_regulation.csv\n",
            "Processed /content/drive/MyDrive/Data folder/calcium_regulation.csv -> /content/drive/MyDrive/Output folder/calcium_regulation.csv\n",
            "Processed /content/drive/MyDrive/Data folder/stress_physiology.csv -> /content/drive/MyDrive/Output folder/stress_physiology.csv\n",
            "Processed /content/drive/MyDrive/Data folder/muscle_activation.csv -> /content/drive/MyDrive/Output folder/muscle_activation.csv\n",
            "Processed /content/drive/MyDrive/Data folder/nerve_reflexes.csv -> /content/drive/MyDrive/Output folder/nerve_reflexes.csv\n",
            "Processed /content/drive/MyDrive/Data folder/autonomic_control.csv -> /content/drive/MyDrive/Output folder/autonomic_control.csv\n",
            "Processed /content/drive/MyDrive/Data folder/neural_plasticity.csv -> /content/drive/MyDrive/Output folder/neural_plasticity.csv\n",
            "Processed /content/drive/MyDrive/Data folder/digestive_control.csv -> /content/drive/MyDrive/Output folder/digestive_control.csv\n",
            "Processed /content/drive/MyDrive/Data folder/nutrient_digestion.csv -> /content/drive/MyDrive/Output folder/nutrient_digestion.csv\n",
            "Processed /content/drive/MyDrive/Data folder/brain_gut_interaction.csv -> /content/drive/MyDrive/Output folder/brain_gut_interaction.csv\n",
            "Processed /content/drive/MyDrive/Data folder/energy_production.csv -> /content/drive/MyDrive/Output folder/energy_production.csv\n",
            "Processed /content/drive/MyDrive/Data folder/oxygen_exchange.csv -> /content/drive/MyDrive/Output folder/oxygen_exchange.csv\n",
            "Processed /content/drive/MyDrive/Data folder/co2_transport.csv -> /content/drive/MyDrive/Output folder/co2_transport.csv\n",
            "Processed /content/drive/MyDrive/Data folder/erythropoiesis_sentences.csv -> /content/drive/MyDrive/Output folder/erythropoiesis_sentences.csv\n",
            "Processed /content/drive/MyDrive/Data folder/hearing_mechanism.csv -> /content/drive/MyDrive/Output folder/hearing_mechanism.csv\n",
            "Processed /content/drive/MyDrive/Data folder/heart_electrical_system.csv -> /content/drive/MyDrive/Output folder/heart_electrical_system.csv\n",
            "Processed /content/drive/MyDrive/Data folder/hemostasis_sentences.csv -> /content/drive/MyDrive/Output folder/hemostasis_sentences.csv\n",
            "Processed /content/drive/MyDrive/Data folder/homeostasis_exercise.csv -> /content/drive/MyDrive/Output folder/homeostasis_exercise.csv\n",
            "Processed /content/drive/MyDrive/Data folder/inflammatory_response.csv -> /content/drive/MyDrive/Output folder/inflammatory_response.csv\n",
            "Processed /content/drive/MyDrive/Data folder/lung_compliance.csv -> /content/drive/MyDrive/Output folder/lung_compliance.csv\n",
            "Processed /content/drive/MyDrive/Data folder/lymphatic_system.csv -> /content/drive/MyDrive/Output folder/lymphatic_system.csv\n",
            "Processed /content/drive/MyDrive/Data folder/muscle_fiber_types.csv -> /content/drive/MyDrive/Output folder/muscle_fiber_types.csv\n",
            "Processed /content/drive/MyDrive/Data folder/nephron_adaptation.csv -> /content/drive/MyDrive/Output folder/nephron_adaptation.csv\n",
            "Processed /content/drive/MyDrive/Data folder/neuromuscular_junction.csv -> /content/drive/MyDrive/Output folder/neuromuscular_junction.csv\n",
            "Processed /content/drive/MyDrive/Data folder/oxygen_hemoglobin_dissociation.csv -> /content/drive/MyDrive/Output folder/oxygen_hemoglobin_dissociation.csv\n",
            "Processed /content/drive/MyDrive/Data folder/pain_perception.csv -> /content/drive/MyDrive/Output folder/pain_perception.csv\n",
            "Processed /content/drive/MyDrive/Data folder/pancreatic_hormones.csv -> /content/drive/MyDrive/Output folder/pancreatic_hormones.csv\n",
            "Processed /content/drive/MyDrive/Data folder/pulmonary_suractant.csv -> /content/drive/MyDrive/Output folder/pulmonary_suractant.csv\n",
            "Processed /content/drive/MyDrive/Data folder/sarcomere_function.csv -> /content/drive/MyDrive/Output folder/sarcomere_function.csv\n",
            "Processed /content/drive/MyDrive/Data folder/shock_types.csv -> /content/drive/MyDrive/Output folder/shock_types.csv\n",
            "Processed /content/drive/MyDrive/Data folder/thermogenesis_explanation.csv -> /content/drive/MyDrive/Output folder/thermogenesis_explanation.csv\n",
            "Processed /content/drive/MyDrive/Data folder/thermoregulation.csv -> /content/drive/MyDrive/Output folder/thermoregulation.csv\n",
            "Processed /content/drive/MyDrive/Data folder/adrenal_medulla.csv -> /content/drive/MyDrive/Output folder/adrenal_medulla.csv\n",
            "Processed /content/drive/MyDrive/Data folder/antibody_production.csv -> /content/drive/MyDrive/Output folder/antibody_production.csv\n",
            "Processed /content/drive/MyDrive/Data folder/arterial_pulse.csv -> /content/drive/MyDrive/Output folder/arterial_pulse.csv\n",
            "Processed /content/drive/MyDrive/Data folder/bone_remodeling.csv -> /content/drive/MyDrive/Output folder/bone_remodeling.csv\n",
            "Processed /content/drive/MyDrive/Data folder/circadian_rhythms.csv -> /content/drive/MyDrive/Output folder/circadian_rhythms.csv\n",
            "Processed /content/drive/MyDrive/Data folder/acid_base_buffers.csv -> /content/drive/MyDrive/Output folder/acid_base_buffers.csv\n",
            "Processed /content/drive/MyDrive/Data folder/action_potential.csv -> /content/drive/MyDrive/Output folder/action_potential.csv\n",
            "Processed /content/drive/MyDrive/Data folder/blood_viscosity.csv -> /content/drive/MyDrive/Output folder/blood_viscosity.csv\n",
            "Processed /content/drive/MyDrive/Data folder/cerebrospinal_fluid.csv -> /content/drive/MyDrive/Output folder/cerebrospinal_fluid.csv\n",
            "Processed /content/drive/MyDrive/Data folder/coronary_circulation.csv -> /content/drive/MyDrive/Output folder/coronary_circulation.csv\n",
            "Processed /content/drive/MyDrive/Data folder/electrolyte_homeostasis.csv -> /content/drive/MyDrive/Output folder/electrolyte_homeostasis.csv\n",
            "Processed /content/drive/MyDrive/Data folder/exercise_metabolism.csv -> /content/drive/MyDrive/Output folder/exercise_metabolism.csv\n",
            "Processed /content/drive/MyDrive/Data folder/fetal_circulation.csv -> /content/drive/MyDrive/Output folder/fetal_circulation.csv\n",
            "Processed /content/drive/MyDrive/Data folder/fever_mechanism.csv -> /content/drive/MyDrive/Output folder/fever_mechanism.csv\n",
            "Processed /content/drive/MyDrive/Data folder/fluid_shifts.csv -> /content/drive/MyDrive/Output folder/fluid_shifts.csv\n",
            "Processed /content/drive/MyDrive/Data folder/growth_hormone_sentences.csv -> /content/drive/MyDrive/Output folder/growth_hormone_sentences.csv\n",
            "Processed /content/drive/MyDrive/Data folder/gut_motility.csv -> /content/drive/MyDrive/Output folder/gut_motility.csv\n",
            "Processed /content/drive/MyDrive/Data folder/hearing_loss_sentences.csv -> /content/drive/MyDrive/Output folder/hearing_loss_sentences.csv\n",
            "Processed /content/drive/MyDrive/Data folder/hormonal_feedback.csv -> /content/drive/MyDrive/Output folder/hormonal_feedback.csv\n",
            "Processed /content/drive/MyDrive/Data folder/hypercapnia_sentences.csv -> /content/drive/MyDrive/Output folder/hypercapnia_sentences.csv\n",
            "Processed /content/drive/MyDrive/Data folder/hypothalamus_functions.csv -> /content/drive/MyDrive/Output folder/hypothalamus_functions.csv\n",
            "Processed /content/drive/MyDrive/Data folder/hypoxia_types.csv -> /content/drive/MyDrive/Output folder/hypoxia_types.csv\n",
            "Processed /content/drive/MyDrive/Data folder/immune_memory.csv -> /content/drive/MyDrive/Output folder/immune_memory.csv\n",
            "Processed /content/drive/MyDrive/Data folder/immune_tolerance.csv -> /content/drive/MyDrive/Output folder/immune_tolerance.csv\n",
            "Processed /content/drive/MyDrive/Data folder/kidney_countercurrent.csv -> /content/drive/MyDrive/Output folder/kidney_countercurrent.csv\n",
            "Processed /content/drive/MyDrive/Data folder/liver_functions.csv -> /content/drive/MyDrive/Output folder/liver_functions.csv\n",
            "Processed /content/drive/MyDrive/Data folder/motor_control.csv -> /content/drive/MyDrive/Output folder/motor_control.csv\n",
            "Processed /content/drive/MyDrive/Data folder/neurotransmitter_roles.csv -> /content/drive/MyDrive/Output folder/neurotransmitter_roles.csv\n",
            "Processed /content/drive/MyDrive/Data folder/pituitary_hormones.csv -> /content/drive/MyDrive/Output folder/pituitary_hormones.csv\n",
            "Processed /content/drive/MyDrive/Data folder/placental_function_sentences.csv -> /content/drive/MyDrive/Output folder/placental_function_sentences.csv\n",
            "Processed /content/drive/MyDrive/Data folder/puberty_hormones.csv -> /content/drive/MyDrive/Output folder/puberty_hormones.csv\n",
            "Processed /content/drive/MyDrive/Data folder/renal_blood_flow.csv -> /content/drive/MyDrive/Output folder/renal_blood_flow.csv\n",
            "Processed /content/drive/MyDrive/Data folder/renal_clearance.csv -> /content/drive/MyDrive/Output folder/renal_clearance.csv\n",
            "Processed /content/drive/MyDrive/Data folder/reproductive_cycle.csv -> /content/drive/MyDrive/Output folder/reproductive_cycle.csv\n",
            "Processed /content/drive/MyDrive/Data folder/respiratory_muscles_sentences.csv -> /content/drive/MyDrive/Output folder/respiratory_muscles_sentences.csv\n",
            "Processed /content/drive/MyDrive/Data folder/sensory_processing.csv -> /content/drive/MyDrive/Output folder/sensory_processing.csv\n",
            "Processed /content/drive/MyDrive/Data folder/spermatogenesis_no_numbers.csv -> /content/drive/MyDrive/Output folder/spermatogenesis_no_numbers.csv\n",
            "Processed /content/drive/MyDrive/Data folder/vascular_resistance.csv -> /content/drive/MyDrive/Output folder/vascular_resistance.csv\n",
            "Processed /content/drive/MyDrive/Data folder/vestibular_system.csv -> /content/drive/MyDrive/Output folder/vestibular_system.csv\n",
            "Processed /content/drive/MyDrive/Data folder/vision_process.csv -> /content/drive/MyDrive/Output folder/vision_process.csv\n",
            "Processed /content/drive/MyDrive/Data folder/altitude_hypoxia.csv -> /content/drive/MyDrive/Output folder/altitude_hypoxia.csv\n",
            "Processed /content/drive/MyDrive/Data folder/anaerobic_threshold_sentences.csv -> /content/drive/MyDrive/Output folder/anaerobic_threshold_sentences.csv\n",
            "Processed /content/drive/MyDrive/Data folder/baroreceptor_reflex.csv -> /content/drive/MyDrive/Output folder/baroreceptor_reflex.csv\n",
            "Processed /content/drive/MyDrive/Data folder/body_adaptation_altitude.csv -> /content/drive/MyDrive/Output folder/body_adaptation_altitude.csv\n",
            "Processed /content/drive/MyDrive/Data folder/chemoreceptor_reflex.csv -> /content/drive/MyDrive/Output folder/chemoreceptor_reflex.csv\n",
            "Processed /content/drive/MyDrive/Data folder/exercise_vasodilation.csv -> /content/drive/MyDrive/Output folder/exercise_vasodilation.csv\n",
            "Processed /content/drive/MyDrive/Data folder/heart_failure_text.csv -> /content/drive/MyDrive/Output folder/heart_failure_text.csv\n",
            "Processed /content/drive/MyDrive/Data folder/ischemia_reperfusion.csv -> /content/drive/MyDrive/Output folder/ischemia_reperfusion.csv\n",
            "Processed /content/drive/MyDrive/Data folder/lactation_data.csv -> /content/drive/MyDrive/Output folder/lactation_data.csv\n",
            "Processed /content/drive/MyDrive/Data folder/lung_volumes.csv -> /content/drive/MyDrive/Output folder/lung_volumes.csv\n",
            "Processed /content/drive/MyDrive/Data folder/peripheral_circulation.csv -> /content/drive/MyDrive/Output folder/peripheral_circulation.csv\n",
            "Processed /content/drive/MyDrive/Data folder/pulmonary_hypertension_sentences.csv -> /content/drive/MyDrive/Output folder/pulmonary_hypertension_sentences.csv\n",
            "Processed /content/drive/MyDrive/Data folder/skin_functions.csv -> /content/drive/MyDrive/Output folder/skin_functions.csv\n",
            "Processed /content/drive/MyDrive/Data folder/starling_forces.csv -> /content/drive/MyDrive/Output folder/starling_forces.csv\n",
            "Processed /content/drive/MyDrive/Data folder/wound_healing.csv -> /content/drive/MyDrive/Output folder/wound_healing.csv\n",
            "Epoch 1/10: Loss = 2.9498, Accuracy = 0.1445\n",
            "Epoch 2/10: Loss = 2.9271, Accuracy = 0.1360\n",
            "Epoch 3/10: Loss = 2.9245, Accuracy = 0.1445\n",
            "Epoch 4/10: Loss = 2.9230, Accuracy = 0.1445\n",
            "Epoch 5/10: Loss = 2.9229, Accuracy = 0.1445\n",
            "Epoch 6/10: Loss = 2.9208, Accuracy = 0.1445\n",
            "Epoch 7/10: Loss = 2.9193, Accuracy = 0.1445\n",
            "Epoch 8/10: Loss = 2.9161, Accuracy = 0.1445\n",
            "Epoch 9/10: Loss = 2.9194, Accuracy = 0.1445\n",
            "Epoch 10/10: Loss = 2.9196, Accuracy = 0.1445\n",
            "Sentence: A gland is an organ that makes one or more substances, such as hormones, digestive juices, sweat or tears.\n",
            "Predicted Label: Definition\n",
            "\n",
            "Sentence: Endocrine glands release hormones directly into the bloodstream.\n",
            "Predicted Label: Definition\n",
            "\n",
            "Sentence: endocrine system is an elaborate network of glands and hormones..\n",
            "Predicted Label: Definition\n",
            "\n",
            "Sentence: A thyroidectomy is the surgical removal of your entire thyroid gland.\n",
            "Predicted Label: Definition\n",
            "\n"
          ]
        }
      ]
    }
  ]
}